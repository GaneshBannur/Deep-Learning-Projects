{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3Vj-6NaOWZ"
      },
      "source": [
        "import torch\r\n",
        "from torch.nn import Linear, CrossEntropyLoss\r\n",
        "from torch.optim import Adam\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision.datasets.folder import default_loader\r\n",
        "from torchvision.transforms import ToTensor, Resize, Compose, RandomGrayscale, RandomHorizontalFlip, RandomResizedCrop\r\n",
        "from torchvision.models import resnet101\r\n",
        "from collections import Counter\r\n",
        "from pathlib import Path\r\n",
        "import os\r\n",
        "from time import time\r\n",
        "import random\r\n",
        "\r\n",
        "from train_and_test_classification import seed_all, train_test_classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Ldxbq6CzrV"
      },
      "source": [
        "seed_all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5s2_6uGyxzT"
      },
      "source": [
        "project_root = Path(\"/project_root\")\r\n",
        "dataset_root = project_root/\"Datasets\"/\"pokemon_dataset\"\r\n",
        "run_folder = project_root/\"runs\"/\"resnet_pokemon_dataset\"\r\n",
        "run_folder.mkdir(exist_ok=True, parents=True)\r\n",
        "current_run_folder = run_folder/f\"{int(time())}\"\r\n",
        "current_run_folder.mkdir(exist_ok=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AV1K6D7epBE"
      },
      "source": [
        "test_network = resnet101(pretrained=False)\r\n",
        "test_network.fc = Linear(2048, 149)\r\n",
        "print(test_network)\r\n",
        "with torch.no_grad():\r\n",
        "  X = torch.ones((1, 3, 224, 224))\r\n",
        "  y = test_network(X)\r\n",
        "  assert y.shape == (1, 149)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuO8VeQUCVvW"
      },
      "source": [
        "def get_file_list(root):\r\n",
        "  if not root.exists():\r\n",
        "        raise FileNotFoundError(f\"Dataset folder doesn't exist. Path : {root}\")\r\n",
        "  filelist = []\r\n",
        "  svg_count = 0\r\n",
        "  subfolders = root.iterdir()\r\n",
        "  subfolders = list(subfolders)\r\n",
        "  for folder in subfolders:\r\n",
        "    if not folder.is_dir():\r\n",
        "      raise ValueError(\"Root Folder should not have files, only subfolders\")\r\n",
        "  classes = [os.path.basename(folder) for folder in subfolders]\r\n",
        "  for folder in subfolders:\r\n",
        "    files = folder.glob(\"*.*\")\r\n",
        "    for file in files:\r\n",
        "      if file.suffix == \".svg\":\r\n",
        "        svg_count = svg_count + 1\r\n",
        "        continue\r\n",
        "      filelist.append(file)\r\n",
        "  print(f\"SVG Number: {svg_count}\")\r\n",
        "  print(f\"Retained: {len(filelist)}\")\r\n",
        "  return filelist, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvLSju2LES58"
      },
      "source": [
        "all_files, classes = get_file_list(dataset_root)\r\n",
        "random.seed(2)\r\n",
        "random.shuffle(all_files)\r\n",
        "train_len = int(0.7 * len(all_files))\r\n",
        "val_len = int(0.15 * len(all_files))\r\n",
        "test_len = len(all_files) - train_len - val_len\r\n",
        "train_files = all_files[:train_len]\r\n",
        "val_files = all_files[train_len:train_len+val_len]\r\n",
        "test_files = all_files[-test_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms4GpC2T-UwX"
      },
      "source": [
        "class ImageDataset(Dataset):\r\n",
        "  def __init__(self, filelist, classes, transforms):\r\n",
        "    self.transforms = transforms\r\n",
        "    self.filelist = filelist\r\n",
        "    labellist = []\r\n",
        "    for file in filelist:\r\n",
        "      folder = file.parent\r\n",
        "      labellist.append(classes.index(os.path.basename(folder)))\r\n",
        "    self.labellist = labellist  \r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    return self.transforms(default_loader(self.filelist[index])), self.labellist[index]\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.labellist)\r\n",
        "\r\n",
        "  def get_label_list(self):\r\n",
        "    return self.labellist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWZkUOIPwqLj"
      },
      "source": [
        "train_data = ImageDataset(filelist=train_files, classes=classes, transforms=Compose([ToTensor(), \r\n",
        "                                                                                     RandomResizedCrop((224,224)), \r\n",
        "                                                                                     RandomHorizontalFlip(), \r\n",
        "                                                                                     RandomGrayscale()]))\r\n",
        "val_data = ImageDataset(filelist=val_files, classes=classes, transforms=Compose([ToTensor(), Resize((224,224))]))\r\n",
        "test_data = ImageDataset(filelist=test_files, classes=classes, transforms=Compose([ToTensor(), Resize((224,224))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Bi6hi42556"
      },
      "source": [
        "train_counts = Counter(train_data.get_label_list())\r\n",
        "val_counts = Counter(val_data.get_label_list())\r\n",
        "test_counts = Counter(test_data.get_label_list())\r\n",
        "\r\n",
        "print(f\"Class Name\\t\\tTrain Count\\tVal Count\\tTest_Count\\n\")\r\n",
        "for class_index, class_name in enumerate(classes):\r\n",
        "  print(f\"{class_name: <20}\\t\\t{train_counts[class_index]}\\t\\t{val_counts[class_index]}\\t\\t{test_counts[class_index]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9DGKpWF6apX"
      },
      "source": [
        "logger = SummaryWriter(current_run_folder/\"logs\")\r\n",
        "model = resnet101(pretrained=True)\r\n",
        "model.fc = Linear(2048, len(classes))\r\n",
        "device = \"cuda\" if torch.cuda.device_count() > 0 else \"cpu\"\r\n",
        "model = model.to(device)\r\n",
        "logger.add_graph(model, torch.ones(1, 3, 224, 224).to(device))\r\n",
        "checkpoint_folder = current_run_folder/\"checkpoints\"\r\n",
        "checkpoint_folder.mkdir(exist_ok=False)\r\n",
        "train_test_classifier(model=model,\r\n",
        "                      train_data=train_data,\r\n",
        "                      val_data=val_data,\r\n",
        "                      test_data=test_data,\r\n",
        "                      batch_size=64,\r\n",
        "                      num_epochs=100,\r\n",
        "                      loss_function=CrossEntropyLoss(),\r\n",
        "                      optimizer=Adam(model.parameters(), lr = 0.0003),\r\n",
        "                      logger=logger,\r\n",
        "                      device=device, \r\n",
        "                      checkpoint_folder=checkpoint_folder,\r\n",
        "                      early_stopping_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}